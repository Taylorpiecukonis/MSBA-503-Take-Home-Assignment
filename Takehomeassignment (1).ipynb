{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3b6d1ad-c3bc-4b5f-b33f-50fa51c1688d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: tensorflow-hub in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: pillow in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (11.1.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from tensorflow-hub) (2.20.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\tpiec\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n",
      "WARNING:tensorflow:From C:\\Users\\tpiec\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "================================================================================\n",
      "MSBA 503 - OBJECT DETECTION ASSIGNMENT\n",
      "================================================================================\n",
      "\n",
      "TensorFlow Version: 2.20.0\n",
      "OpenCV Version: 4.12.0\n",
      "NumPy Version: 2.1.3\n",
      "\n",
      "✓ All libraries imported successfully!\n",
      "\n",
      "Configuration:\n",
      "  Image Folder: images\n",
      "  Confidence Threshold: 0.3\n",
      "  Max Display Objects: 5\n",
      "\n",
      "✓ Loaded 80 COCO object classes\n",
      "\n",
      "================================================================================\n",
      "LOADING DEEP LEARNING MODELS\n",
      "================================================================================\n",
      "\n",
      "This will download models on first run (~2-3 minutes)\n",
      "Subsequent runs will be instant!\n",
      "\n",
      "Loading Model 1: SSD MobileNet V2...\n",
      "WARNING:tensorflow:From C:\\Users\\tpiec\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tpiec\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tpiec\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tpiec\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ SSD MobileNet V2 loaded successfully!\n",
      "\n",
      "Loading Model 2: EfficientDet D0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference___call___32344) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_97451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_77595) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_103456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_93843) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_107064) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_75975) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ EfficientDet D0 loaded successfully!\n",
      "\n",
      "✓ Both models loaded successfully!\n",
      "\n",
      "✓ Object detection function defined\n",
      "\n",
      "✓ Feature extraction function defined\n",
      "\n",
      "✓ Found 11 images in 'images' folder\n",
      "\n",
      "Images found:\n",
      "  1. 1000_F_187616108_v8oMYk5q7rKJXtZOfWOLoz51HcVu0JZl.jpg\n",
      "  2. 360_F_310422728_gvGj4cxa8MZDbJOPws9MgQXUslt7jpxF.jpg\n",
      "  3. DSC6580-684x1024.jpg\n",
      "  4. coconuts-on-beach-place-milk-260nw-1026353836.webp\n",
      "  5. empty-classroom-scene-with-interior-decoration-and-objects-free-vector.jpg\n",
      "  ... and 6 more\n",
      "\n",
      "================================================================================\n",
      "PROCESSING 11 IMAGES\n",
      "================================================================================\n",
      "\n",
      "[1/11] Processing: 1000_F_187616108_v8oMYk5q7rKJXtZOfWOLoz51HcVu0JZl\n",
      "------------------------------------------------------------\n",
      "  Running object detection...\n",
      "    SSD MobileNet V2     | Time: 5.6999s | Objects: 100 | Conf: 0.3788\n",
      "      → chair, chair, chair, chair, chair\n",
      "    EfficientDet D0      | Time: 10.1763s | Objects: 11 | Conf: 0.4580\n",
      "      → chair, potted plant, laptop, chair, chair\n",
      "\n",
      "  Extracting additional features...\n",
      "    • Dimensions: 1000x714\n",
      "    • Faces: 0, Eyes: 5\n",
      "    • Edge Density: 5.95%\n",
      "    • Brightness: 172.85, Contrast: 53.84\n",
      "    • Dominant Color: RGB(172, 167, 161)\n",
      "    • Corners: 5751, Blur: 1041.08\n",
      "\n",
      "[2/11] Processing: 360_F_310422728_gvGj4cxa8MZDbJOPws9MgQXUslt7jpxF\n",
      "------------------------------------------------------------\n",
      "  Running object detection...\n",
      "    SSD MobileNet V2     | Time: 0.8915s | Objects: 74 | Conf: 0.4128\n",
      "      → car, car, car, car, potted plant\n",
      "    EfficientDet D0      | Time: 2.6096s | Objects: 10 | Conf: 0.5646\n",
      "      → car, car, car, potted plant, potted plant\n",
      "\n",
      "  Extracting additional features...\n",
      "    • Dimensions: 540x360\n",
      "    • Faces: 1, Eyes: 1\n",
      "    • Edge Density: 22.49%\n",
      "    • Brightness: 156.4, Contrast: 67.44\n",
      "    • Dominant Color: RGB(136, 121, 112)\n",
      "    • Corners: 7775, Blur: 5026.74\n",
      "\n",
      "[3/11] Processing: DSC6580-684x1024\n",
      "------------------------------------------------------------\n",
      "  Running object detection...\n",
      "    SSD MobileNet V2     | Time: 0.7558s | Objects: 35 | Conf: 0.4198\n",
      "      → potted plant, potted plant, dog, bowl, chair\n",
      "    EfficientDet D0      | Time: 2.6005s | Objects:  8 | Conf: 0.5657\n",
      "      → cat, cat, cat, potted plant, potted plant\n",
      "\n",
      "  Extracting additional features...\n",
      "    • Dimensions: 684x1024\n",
      "    • Faces: 0, Eyes: 0\n",
      "    • Edge Density: 10.33%\n",
      "    • Brightness: 147.36, Contrast: 66.49\n",
      "    • Dominant Color: RGB(141, 129, 116)\n",
      "    • Corners: 8662, Blur: 693.64\n",
      "\n",
      "[4/11] Processing: coconuts-on-beach-place-milk-260nw-1026353836\n",
      "------------------------------------------------------------\n",
      "  Running object detection...\n",
      "    SSD MobileNet V2     | Time: 0.7036s | Objects: 14 | Conf: 0.4158\n",
      "      → bed, teddy bear, teddy bear, donut, teddy bear\n",
      "    EfficientDet D0      | Time: 2.3278s | Objects:  3 | Conf: 0.3458\n",
      "      → teddy bear, teddy bear, bed\n",
      "\n",
      "  Extracting additional features...\n",
      "    • Dimensions: 390x280\n",
      "    • Faces: 0, Eyes: 1\n",
      "    • Edge Density: 11.09%\n",
      "    • Brightness: 197.02, Contrast: 61.57\n",
      "    • Dominant Color: RGB(160, 176, 158)\n",
      "    • Corners: 1717, Blur: 2339.14\n",
      "\n",
      "[5/11] Processing: empty-classroom-scene-with-interior-decoration-and-objects-free-vector\n",
      "------------------------------------------------------------\n",
      "  Running object detection...\n",
      "    SSD MobileNet V2     | Time: 1.1956s | Objects: 100 | Conf: 0.4037\n",
      "      → chair, chair, book, dining table, dining table\n",
      "    EfficientDet D0      | Time: 2.9359s | Objects: 16 | Conf: 0.3740\n",
      "      → chair, dining table, dining table, chair, dining table\n",
      "\n",
      "  Extracting additional features...\n",
      "    • Dimensions: 1736x980\n",
      "    • Faces: 0, Eyes: 0\n",
      "    • Edge Density: 6.15%\n",
      "    • Brightness: 174.16, Contrast: 59.41\n",
      "    • Dominant Color: RGB(143, 145, 110)\n",
      "    • Corners: 3867, Blur: 446.22\n",
      "\n",
      "[6/11] Processing: img-A-Guide-to-Choosing-the-Best-Toys-for-Your-Dog\n",
      "------------------------------------------------------------\n",
      "  Running object detection...\n",
      "    SSD MobileNet V2     | Time: 0.8946s | Objects:  3 | Conf: 0.5016\n",
      "      → dog, sports ball, kite\n",
      "    EfficientDet D0      | Time: 2.4215s | Objects:  2 | Conf: 0.8860\n",
      "      → dog, sports ball\n",
      "\n",
      "  Extracting additional features...\n",
      "    • Dimensions: 1024x688\n",
      "    • Faces: 1, Eyes: 8\n",
      "    • Edge Density: 2.38%\n",
      "    • Brightness: 237.5, Contrast: 41.14\n",
      "    • Dominant Color: RGB(233, 211, 115)\n",
      "    • Corners: 555, Blur: 169.48\n",
      "\n",
      "[7/11] Processing: istockphoto-1755563909-612x612\n",
      "------------------------------------------------------------\n",
      "  Running object detection...\n",
      "    SSD MobileNet V2     | Time: 0.2863s | Objects: 54 | Conf: 0.4135\n",
      "      → oven, oven, knife, knife, spoon\n",
      "    EfficientDet D0      | Time: 0.9452s | Objects:  3 | Conf: 0.5187\n",
      "      → oven, potted plant, bottle\n",
      "\n",
      "  Extracting additional features...\n",
      "    • Dimensions: 612x408\n",
      "    • Faces: 0, Eyes: 1\n",
      "    • Edge Density: 7.67%\n",
      "    • Brightness: 157.67, Contrast: 63.89\n",
      "    • Dominant Color: RGB(156, 153, 144)\n",
      "    • Corners: 1980, Blur: 868.57\n",
      "\n",
      "[8/11] Processing: istockphoto-495977454-612x612\n",
      "------------------------------------------------------------\n",
      "  Running object detection...\n",
      "    SSD MobileNet V2     | Time: 0.3590s | Objects:  3 | Conf: 0.5988\n",
      "      → person, person, person\n",
      "    EfficientDet D0      | Time: 0.8601s | Objects:  3 | Conf: 0.3900\n",
      "      → person, frisbee, person\n",
      "\n",
      "  Extracting additional features...\n",
      "    • Dimensions: 612x408\n",
      "    • Faces: 0, Eyes: 0\n",
      "    • Edge Density: 11.76%\n",
      "    • Brightness: 188.3, Contrast: 71.69\n",
      "    • Dominant Color: RGB(185, 167, 120)\n",
      "    • Corners: 13263, Blur: 1784.68\n",
      "\n",
      "[9/11] Processing: pexels-ash-craig-122861-376464\n",
      "------------------------------------------------------------\n",
      "  Running object detection...\n",
      "    SSD MobileNet V2     | Time: 0.2880s | Objects: 20 | Conf: 0.4161\n",
      "      → cake, bowl, dining table, cup, sandwich\n",
      "    EfficientDet D0      | Time: 0.8415s | Objects:  4 | Conf: 0.5513\n",
      "      → cake, bowl, dining table, knife\n",
      "\n",
      "  Extracting additional features...\n",
      "    • Dimensions: 2841x1735\n",
      "    • Faces: 1, Eyes: 27\n",
      "    • Edge Density: 2.07%\n",
      "    • Brightness: 143.41, Contrast: 67.05\n",
      "    • Dominant Color: RGB(134, 125, 114)\n",
      "    • Corners: 9673, Blur: 143.42\n",
      "\n",
      "[10/11] Processing: pexels-ella-olsson-572949-1640777\n",
      "------------------------------------------------------------\n",
      "  Running object detection...\n",
      "    SSD MobileNet V2     | Time: 0.3438s | Objects: 100 | Conf: 0.4202\n",
      "      → bowl, carrot, carrot, carrot, carrot\n",
      "    EfficientDet D0      | Time: 0.8612s | Objects: 18 | Conf: 0.4209\n",
      "      → fork, carrot, dining table, broccoli, carrot\n",
      "\n",
      "  Extracting additional features...\n",
      "    • Dimensions: 4288x2859\n",
      "    • Faces: 7, Eyes: 38\n",
      "    • Edge Density: 8.05%\n",
      "    • Brightness: 203.29, Contrast: 62.77\n",
      "    • Dominant Color: RGB(197, 182, 162)\n",
      "    • Corners: 114717, Blur: 792.97\n",
      "\n",
      "[11/11] Processing: remove-distracting-objects_step1\n",
      "------------------------------------------------------------\n",
      "  Running object detection...\n",
      "    SSD MobileNet V2     | Time: 0.3181s | Objects: 16 | Conf: 0.3785\n",
      "      → umbrella, person, person, person, potted plant\n",
      "    EfficientDet D0      | Time: 0.8692s | Objects:  4 | Conf: 0.4588\n",
      "      → boat, surfboard, surfboard, surfboard\n",
      "\n",
      "  Extracting additional features...\n",
      "    • Dimensions: 1800x1200\n",
      "    • Faces: 1, Eyes: 0\n",
      "    • Edge Density: 7.89%\n",
      "    • Brightness: 174.98, Contrast: 49.63\n",
      "    • Dominant Color: RGB(130, 143, 148)\n",
      "    • Corners: 10878, Blur: 615.78\n",
      "\n",
      "================================================================================\n",
      "✓ PROCESSING COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "SUMMARY STATISTICS\n",
      "================================================================================\n",
      "\n",
      "SSD MobileNet V2:\n",
      "  Average Detection Time:    1.0669 seconds\n",
      "  Average Objects Detected:  47.18 objects\n",
      "  Average Confidence Score:  0.4327\n",
      "\n",
      "EfficientDet D0:\n",
      "  Average Detection Time:    2.4953 seconds\n",
      "  Average Objects Detected:  7.45 objects\n",
      "  Average Confidence Score:  0.5031\n",
      "\n",
      "Performance Comparison:\n",
      "  EfficientDet D0 is 133.9% slower than SSD MobileNet V2\n",
      "  EfficientDet D0 detects 84.2% fewer objects\n",
      "  EfficientDet D0 has 16.3% higher confidence\n",
      "\n",
      "================================================================================\n",
      "CREATING OUTPUT FILES\n",
      "================================================================================\n",
      "\n",
      "✓ Part A(i) saved to: part_a_i_detection_comparison.csv\n",
      "\n",
      "Part A(i) - Detection Comparison Table:\n",
      "                                                            Image Name            Model  Detection Time (s)  Objects Detected  Avg Confidence                                                  Detected Objects\n",
      "                     1000_F_187616108_v8oMYk5q7rKJXtZOfWOLoz51HcVu0JZl SSD MobileNet V2              5.6999               100          0.3788                      chair, chair, chair, chair, chair (+95 more)\n",
      "                     1000_F_187616108_v8oMYk5q7rKJXtZOfWOLoz51HcVu0JZl  EfficientDet D0             10.1763                11          0.4580               chair, potted plant, laptop, chair, chair (+6 more)\n",
      "                      360_F_310422728_gvGj4cxa8MZDbJOPws9MgQXUslt7jpxF SSD MobileNet V2              0.8915                74          0.4128                       car, car, car, car, potted plant (+69 more)\n",
      "                      360_F_310422728_gvGj4cxa8MZDbJOPws9MgQXUslt7jpxF  EfficientDet D0              2.6096                10          0.5646               car, car, car, potted plant, potted plant (+5 more)\n",
      "                                                      DSC6580-684x1024 SSD MobileNet V2              0.7558                35          0.4198           potted plant, potted plant, dog, bowl, chair (+30 more)\n",
      "                                                      DSC6580-684x1024  EfficientDet D0              2.6005                 8          0.5657               cat, cat, cat, potted plant, potted plant (+3 more)\n",
      "                         coconuts-on-beach-place-milk-260nw-1026353836 SSD MobileNet V2              0.7036                14          0.4158          bed, teddy bear, teddy bear, donut, teddy bear (+9 more)\n",
      "                         coconuts-on-beach-place-milk-260nw-1026353836  EfficientDet D0              2.3278                 3          0.3458                                       teddy bear, teddy bear, bed\n",
      "empty-classroom-scene-with-interior-decoration-and-objects-free-vector SSD MobileNet V2              1.1956               100          0.4037         chair, chair, book, dining table, dining table (+95 more)\n",
      "empty-classroom-scene-with-interior-decoration-and-objects-free-vector  EfficientDet D0              2.9359                16          0.3740 chair, dining table, dining table, chair, dining table (+11 more)\n",
      "                    img-A-Guide-to-Choosing-the-Best-Toys-for-Your-Dog SSD MobileNet V2              0.8946                 3          0.5016                                            dog, sports ball, kite\n",
      "                    img-A-Guide-to-Choosing-the-Best-Toys-for-Your-Dog  EfficientDet D0              2.4215                 2          0.8860                                                  dog, sports ball\n",
      "                                        istockphoto-1755563909-612x612 SSD MobileNet V2              0.2863                54          0.4135                        oven, oven, knife, knife, spoon (+49 more)\n",
      "                                        istockphoto-1755563909-612x612  EfficientDet D0              0.9452                 3          0.5187                                        oven, potted plant, bottle\n",
      "                                         istockphoto-495977454-612x612 SSD MobileNet V2              0.3590                 3          0.5988                                            person, person, person\n",
      "                                         istockphoto-495977454-612x612  EfficientDet D0              0.8601                 3          0.3900                                           person, frisbee, person\n",
      "                                        pexels-ash-craig-122861-376464 SSD MobileNet V2              0.2880                20          0.4161                cake, bowl, dining table, cup, sandwich (+15 more)\n",
      "                                        pexels-ash-craig-122861-376464  EfficientDet D0              0.8415                 4          0.5513                                   cake, bowl, dining table, knife\n",
      "                                     pexels-ella-olsson-572949-1640777 SSD MobileNet V2              0.3438               100          0.4202                   bowl, carrot, carrot, carrot, carrot (+95 more)\n",
      "                                     pexels-ella-olsson-572949-1640777  EfficientDet D0              0.8612                18          0.4209           fork, carrot, dining table, broccoli, carrot (+13 more)\n",
      "                                      remove-distracting-objects_step1 SSD MobileNet V2              0.3181                16          0.3785         umbrella, person, person, person, potted plant (+11 more)\n",
      "                                      remove-distracting-objects_step1  EfficientDet D0              0.8692                 4          0.4588                             boat, surfboard, surfboard, surfboard\n",
      "\n",
      "✓ Part A(ii) saved to: part_a_ii_additional_features.csv\n",
      "\n",
      "Part A(ii) - Additional Features Table:\n",
      "                                                                 image dimensions  num_faces  num_eyes  edge_density_percent  brightness_level  contrast_level dominant_color_rgb  color_variance  num_corners  blur_score\n",
      "                     1000_F_187616108_v8oMYk5q7rKJXtZOfWOLoz51HcVu0JZl   1000x714          0         5                  5.95            172.85           53.84    (172, 167, 161)         2963.32         5751     1041.08\n",
      "                      360_F_310422728_gvGj4cxa8MZDbJOPws9MgQXUslt7jpxF    540x360          1         1                 22.49            156.40           67.44    (136, 121, 112)         6085.49         7775     5026.74\n",
      "                                                      DSC6580-684x1024   684x1024          0         0                 10.33            147.36           66.49    (141, 129, 116)         4776.75         8662      693.64\n",
      "                         coconuts-on-beach-place-milk-260nw-1026353836    390x280          0         1                 11.09            197.02           61.57    (160, 176, 158)         5647.67         1717     2339.14\n",
      "empty-classroom-scene-with-interior-decoration-and-objects-free-vector   1736x980          0         0                  6.15            174.16           59.41    (143, 145, 110)         5123.11         3867      446.22\n",
      "                    img-A-Guide-to-Choosing-the-Best-Toys-for-Your-Dog   1024x688          1         8                  2.38            237.50           41.14    (233, 211, 115)         4581.20          555      169.48\n",
      "                                        istockphoto-1755563909-612x612    612x408          0         1                  7.67            157.67           63.89    (156, 153, 144)         4220.36         1980      868.57\n",
      "                                         istockphoto-495977454-612x612    612x408          0         0                 11.76            188.30           71.69    (185, 167, 120)         7537.81        13263     1784.68\n",
      "                                        pexels-ash-craig-122861-376464  2841x1735          1        27                  2.07            143.41           67.05    (134, 125, 114)         5103.85         9673      143.42\n",
      "                                     pexels-ella-olsson-572949-1640777  4288x2859          7        38                  8.05            203.29           62.77    (197, 182, 162)         5391.76       114717      792.97\n",
      "                                      remove-distracting-objects_step1  1800x1200          1         0                  7.89            174.98           49.63    (130, 143, 148)         3881.24        10878      615.78\n",
      "\n",
      "✓ Detailed results saved to: detailed_results.json\n",
      "\n",
      "================================================================================\n",
      "✓ ALL FILES GENERATED SUCCESSFULLY!\n",
      "================================================================================\n",
      "\n",
      "Generated files:\n",
      "  1. part_a_i_detection_comparison.csv  - For Part A(i) in Word\n",
      "  2. part_a_ii_additional_features.csv  - For Part A(ii) in Word\n",
      "  3. detailed_results.json              - Full detailed results\n",
      "\n",
      "You can now copy these tables into your Word document!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MSBA 503 Take-Home Assignment - Object Detection\n",
    "Jupyter Notebook Version - Ready for Teacher Testing\n",
    "\n",
    "Author: Taylor Piecukonis\n",
    "Date: December 2025\n",
    "\n",
    "SETUP INSTRUCTIONS:\n",
    "1. Run: !pip install tensorflow tensorflow-hub opencv-python numpy pillow pandas matplotlib\n",
    "2. Create folder named 'images' in same directory as this notebook\n",
    "3. Add your images to the 'images' folder\n",
    "4. Run all cells in order\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install tensorflow tensorflow-hub opencv-python pillow pandas matplotlib\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 1: INSTALL AND IMPORT LIBRARIES\n",
    "# ============================================================================\n",
    "\n",
    "# Uncomment the line below to install required packages in Jupyter\n",
    "# !pip install tensorflow tensorflow-hub opencv-python numpy pillow pandas matplotlib\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MSBA 503 - OBJECT DETECTION ASSIGNMENT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTensorFlow Version: {tf.__version__}\")\n",
    "print(f\"OpenCV Version: {cv2.__version__}\")\n",
    "print(f\"NumPy Version: {np.__version__}\")\n",
    "print(\"\\n✓ All libraries imported successfully!\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 2: CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Configuration settings\n",
    "IMAGE_FOLDER = 'images'  # Folder containing your images\n",
    "CONFIDENCE_THRESHOLD = 0.3  # Minimum confidence for detections (30%)\n",
    "MAX_DISPLAY_OBJECTS = 5  # Max objects to display per image\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Image Folder: {IMAGE_FOLDER}\")\n",
    "print(f\"  Confidence Threshold: {CONFIDENCE_THRESHOLD}\")\n",
    "print(f\"  Max Display Objects: {MAX_DISPLAY_OBJECTS}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 3: COCO CLASS NAMES\n",
    "# ============================================================================\n",
    "\n",
    "# COCO dataset class names (80 object classes)\n",
    "COCO_CLASSES = {\n",
    "    1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane',\n",
    "    6: 'bus', 7: 'train', 8: 'truck', 9: 'boat', 10: 'traffic light',\n",
    "    11: 'fire hydrant', 13: 'stop sign', 14: 'parking meter', 15: 'bench',\n",
    "    16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse', 20: 'sheep',\n",
    "    21: 'cow', 22: 'elephant', 23: 'bear', 24: 'zebra', 25: 'giraffe',\n",
    "    27: 'backpack', 28: 'umbrella', 31: 'handbag', 32: 'tie', 33: 'suitcase',\n",
    "    34: 'frisbee', 35: 'skis', 36: 'snowboard', 37: 'sports ball', 38: 'kite',\n",
    "    39: 'baseball bat', 40: 'baseball glove', 41: 'skateboard', 42: 'surfboard',\n",
    "    43: 'tennis racket', 44: 'bottle', 46: 'wine glass', 47: 'cup',\n",
    "    48: 'fork', 49: 'knife', 50: 'spoon', 51: 'bowl', 52: 'banana',\n",
    "    53: 'apple', 54: 'sandwich', 55: 'orange', 56: 'broccoli', 57: 'carrot',\n",
    "    58: 'hot dog', 59: 'pizza', 60: 'donut', 61: 'cake', 62: 'chair',\n",
    "    63: 'couch', 64: 'potted plant', 65: 'bed', 67: 'dining table',\n",
    "    70: 'toilet', 72: 'tv', 73: 'laptop', 74: 'mouse', 75: 'remote',\n",
    "    76: 'keyboard', 77: 'cell phone', 78: 'microwave', 79: 'oven',\n",
    "    80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book',\n",
    "    85: 'clock', 86: 'vase', 87: 'scissors', 88: 'teddy bear',\n",
    "    89: 'hair drier', 90: 'toothbrush'\n",
    "}\n",
    "\n",
    "def get_class_name(class_id):\n",
    "    \"\"\"Convert class ID to readable name\"\"\"\n",
    "    return COCO_CLASSES.get(class_id, f'unknown_class_{class_id}')\n",
    "\n",
    "print(f\"✓ Loaded {len(COCO_CLASSES)} COCO object classes\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 4: LOAD DEEP LEARNING MODELS (PART A-i)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING DEEP LEARNING MODELS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nThis will download models on first run (~2-3 minutes)\")\n",
    "print(\"Subsequent runs will be instant!\\n\")\n",
    "\n",
    "# Model 1: SSD MobileNet V2 (Fast and efficient)\n",
    "print(\"Loading Model 1: SSD MobileNet V2...\")\n",
    "try:\n",
    "    model1 = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\")\n",
    "    model1_name = \"SSD MobileNet V2\"\n",
    "    print(\"✓ SSD MobileNet V2 loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error loading Model 1: {e}\")\n",
    "    model1 = None\n",
    "\n",
    "print()\n",
    "\n",
    "# Model 2: EfficientDet D0 (More accurate)\n",
    "print(\"Loading Model 2: EfficientDet D0...\")\n",
    "try:\n",
    "    model2 = hub.load(\"https://tfhub.dev/tensorflow/efficientdet/d0/1\")\n",
    "    model2_name = \"EfficientDet D0\"\n",
    "    print(\"✓ EfficientDet D0 loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error loading Model 2: {e}\")\n",
    "    model2 = None\n",
    "\n",
    "print(\"\\n✓ Both models loaded successfully!\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 5: OBJECT DETECTION FUNCTION (PART A-i)\n",
    "# ============================================================================\n",
    "\n",
    "def detect_objects(model, model_name, image_path, image_name):\n",
    "    \"\"\"\n",
    "    Perform object detection on an image\n",
    "    \n",
    "    Args:\n",
    "        model: TensorFlow Hub detection model\n",
    "        model_name: Name of the model\n",
    "        image_path: Path to image file\n",
    "        image_name: Name for display\n",
    "        \n",
    "    Returns:\n",
    "        dict: Detection results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and preprocess image\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"  ✗ Error: Could not load {image_path}\")\n",
    "            return None\n",
    "        \n",
    "        # Convert BGR to RGB\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        input_tensor = tf.convert_to_tensor(img_rgb)\n",
    "        input_tensor = input_tensor[tf.newaxis, ...]\n",
    "        \n",
    "        # Run detection and measure time\n",
    "        start_time = time.time()\n",
    "        detections = model(input_tensor)\n",
    "        detection_time = time.time() - start_time\n",
    "        \n",
    "        # Extract results\n",
    "        num_detections = int(detections.pop('num_detections'))\n",
    "        detections = {key: value[0, :num_detections].numpy()\n",
    "                     for key, value in detections.items()}\n",
    "        \n",
    "        detection_classes = detections['detection_classes'].astype(np.int64)\n",
    "        detection_scores = detections['detection_scores']\n",
    "        \n",
    "        # Filter by confidence threshold\n",
    "        detected_objects = []\n",
    "        for i in range(num_detections):\n",
    "            if detection_scores[i] >= CONFIDENCE_THRESHOLD:\n",
    "                detected_objects.append({\n",
    "                    'class_id': int(detection_classes[i]),\n",
    "                    'class_name': get_class_name(detection_classes[i]),\n",
    "                    'confidence': float(detection_scores[i])\n",
    "                })\n",
    "        \n",
    "        # Calculate average confidence\n",
    "        avg_confidence = np.mean([obj['confidence'] for obj in detected_objects]) if detected_objects else 0\n",
    "        \n",
    "        return {\n",
    "            'image': image_name,\n",
    "            'model': model_name,\n",
    "            'detection_time_seconds': round(detection_time, 4),\n",
    "            'num_objects_detected': len(detected_objects),\n",
    "            'average_confidence': round(avg_confidence, 4),\n",
    "            'detected_objects': detected_objects\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error processing {image_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"✓ Object detection function defined\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 6: ADDITIONAL FEATURE EXTRACTION (PART A-ii)\n",
    "# ============================================================================\n",
    "\n",
    "def extract_additional_features(image_path, image_name):\n",
    "    \"\"\"\n",
    "    Extract additional features using computer vision techniques\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to image file\n",
    "        image_name: Name for display\n",
    "        \n",
    "    Returns:\n",
    "        dict: Extracted features\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load image\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            return None\n",
    "        \n",
    "        # Convert to different color spaces\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # 1. Image dimensions\n",
    "        height, width = img.shape[:2]\n",
    "        dimensions = f\"{width}x{height}\"\n",
    "        \n",
    "        # 2. Face detection (Haar Cascade)\n",
    "        face_cascade = cv2.CascadeClassifier(\n",
    "            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "        )\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(30, 30))\n",
    "        num_faces = len(faces)\n",
    "        \n",
    "        # 3. Eye detection (Haar Cascade)\n",
    "        eye_cascade = cv2.CascadeClassifier(\n",
    "            cv2.data.haarcascades + 'haarcascade_eye.xml'\n",
    "        )\n",
    "        eyes = eye_cascade.detectMultiScale(gray, 1.1, 5, minSize=(20, 20))\n",
    "        num_eyes = len(eyes)\n",
    "        \n",
    "        # 4. Edge detection (Canny)\n",
    "        edges = cv2.Canny(gray, 100, 200)\n",
    "        edge_density = (np.sum(edges > 0) / edges.size) * 100\n",
    "        \n",
    "        # 5. Brightness (HSV V channel)\n",
    "        brightness = np.mean(hsv[:, :, 2])\n",
    "        \n",
    "        # 6. Contrast (standard deviation)\n",
    "        contrast = np.std(gray)\n",
    "        \n",
    "        # 7. Dominant color (average RGB)\n",
    "        avg_r = int(np.mean(img_rgb[:, :, 0]))\n",
    "        avg_g = int(np.mean(img_rgb[:, :, 1]))\n",
    "        avg_b = int(np.mean(img_rgb[:, :, 2]))\n",
    "        dominant_color = f\"({avg_r}, {avg_g}, {avg_b})\"\n",
    "        \n",
    "        # 8. Color variance\n",
    "        color_variance = np.var(img_rgb)\n",
    "        \n",
    "        # 9. Corner detection (Harris)\n",
    "        gray_float = np.float32(gray)\n",
    "        dst = cv2.cornerHarris(gray_float, 2, 3, 0.04)\n",
    "        num_corners = int(np.sum(dst > 0.01 * dst.max()))\n",
    "        \n",
    "        # 10. Blur detection (Laplacian variance)\n",
    "        blur_score = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "        \n",
    "        return {\n",
    "            'image': image_name,\n",
    "            'dimensions': dimensions,\n",
    "            'num_faces': num_faces,\n",
    "            'num_eyes': num_eyes,\n",
    "            'edge_density_percent': round(edge_density, 2),\n",
    "            'brightness_level': round(brightness, 2),\n",
    "            'contrast_level': round(contrast, 2),\n",
    "            'dominant_color_rgb': dominant_color,\n",
    "            'color_variance': round(color_variance, 2),\n",
    "            'num_corners': num_corners,\n",
    "            'blur_score': round(blur_score, 2)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error extracting features from {image_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"✓ Feature extraction function defined\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 7: GET IMAGES FROM FOLDER\n",
    "# ============================================================================\n",
    "\n",
    "# Check if image folder exists\n",
    "if not os.path.exists(IMAGE_FOLDER):\n",
    "    os.makedirs(IMAGE_FOLDER)\n",
    "    print(f\"✓ Created folder: {IMAGE_FOLDER}\")\n",
    "    print(f\"\\n⚠ Please add at least 10 images to the '{IMAGE_FOLDER}' folder\")\n",
    "    print(\"   Supported formats: .jpg, .jpeg, .png, .bmp, .tiff, .webp\\n\")\n",
    "    image_files = []\n",
    "else:\n",
    "    # Get all image files\n",
    "    extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp')\n",
    "    image_files = [f for f in os.listdir(IMAGE_FOLDER) \n",
    "                  if f.lower().endswith(extensions)]\n",
    "    image_files = sorted(image_files)\n",
    "    \n",
    "    print(f\"✓ Found {len(image_files)} images in '{IMAGE_FOLDER}' folder\")\n",
    "    \n",
    "    if len(image_files) < 10:\n",
    "        print(f\"⚠ Warning: Assignment requires at least 10 images. You have {len(image_files)}.\")\n",
    "    \n",
    "    if image_files:\n",
    "        print(\"\\nImages found:\")\n",
    "        for i, img in enumerate(image_files[:5], 1):\n",
    "            print(f\"  {i}. {img}\")\n",
    "        if len(image_files) > 5:\n",
    "            print(f\"  ... and {len(image_files) - 5} more\")\n",
    "    print()\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 8: PROCESS ALL IMAGES\n",
    "# ============================================================================\n",
    "\n",
    "if not image_files:\n",
    "    print(\"⚠ No images to process. Please add images and run again.\")\n",
    "else:\n",
    "    print(\"=\"*80)\n",
    "    print(f\"PROCESSING {len(image_files)} IMAGES\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    \n",
    "    # Store all results\n",
    "    all_detection_results = []\n",
    "    all_feature_results = []\n",
    "    \n",
    "    # Process each image\n",
    "    for idx, image_file in enumerate(image_files, 1):\n",
    "        image_path = os.path.join(IMAGE_FOLDER, image_file)\n",
    "        image_name = os.path.splitext(image_file)[0]\n",
    "        \n",
    "        print(f\"[{idx}/{len(image_files)}] Processing: {image_name}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # PART A(i): Object Detection with both models\n",
    "        print(\"  Running object detection...\")\n",
    "        \n",
    "        if model1:\n",
    "            result1 = detect_objects(model1, model1_name, image_path, image_name)\n",
    "            if result1:\n",
    "                objects_list = [obj['class_name'] for obj in result1['detected_objects'][:MAX_DISPLAY_OBJECTS]]\n",
    "                print(f\"    {result1['model']:<20} | \"\n",
    "                      f\"Time: {result1['detection_time_seconds']:.4f}s | \"\n",
    "                      f\"Objects: {result1['num_objects_detected']:2} | \"\n",
    "                      f\"Conf: {result1['average_confidence']:.4f}\")\n",
    "                if objects_list:\n",
    "                    print(f\"      → {', '.join(objects_list)}\")\n",
    "                all_detection_results.append(result1)\n",
    "        \n",
    "        if model2:\n",
    "            result2 = detect_objects(model2, model2_name, image_path, image_name)\n",
    "            if result2:\n",
    "                objects_list = [obj['class_name'] for obj in result2['detected_objects'][:MAX_DISPLAY_OBJECTS]]\n",
    "                print(f\"    {result2['model']:<20} | \"\n",
    "                      f\"Time: {result2['detection_time_seconds']:.4f}s | \"\n",
    "                      f\"Objects: {result2['num_objects_detected']:2} | \"\n",
    "                      f\"Conf: {result2['average_confidence']:.4f}\")\n",
    "                if objects_list:\n",
    "                    print(f\"      → {', '.join(objects_list)}\")\n",
    "                all_detection_results.append(result2)\n",
    "        \n",
    "        # PART A(ii): Additional Feature Extraction\n",
    "        print(\"\\n  Extracting additional features...\")\n",
    "        features = extract_additional_features(image_path, image_name)\n",
    "        \n",
    "        if features:\n",
    "            print(f\"    • Dimensions: {features['dimensions']}\")\n",
    "            print(f\"    • Faces: {features['num_faces']}, Eyes: {features['num_eyes']}\")\n",
    "            print(f\"    • Edge Density: {features['edge_density_percent']}%\")\n",
    "            print(f\"    • Brightness: {features['brightness_level']}, \"\n",
    "                  f\"Contrast: {features['contrast_level']}\")\n",
    "            print(f\"    • Dominant Color: RGB{features['dominant_color_rgb']}\")\n",
    "            print(f\"    • Corners: {features['num_corners']}, \"\n",
    "                  f\"Blur: {features['blur_score']}\")\n",
    "            all_feature_results.append(features)\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"✓ PROCESSING COMPLETE!\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 9: GENERATE SUMMARY STATISTICS\n",
    "# ============================================================================\n",
    "\n",
    "if all_detection_results:\n",
    "    print(\"=\"*80)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    \n",
    "    # Group by model\n",
    "    model1_results = [r for r in all_detection_results if r['model'] == model1_name]\n",
    "    model2_results = [r for r in all_detection_results if r['model'] == model2_name]\n",
    "    \n",
    "    # Calculate statistics for Model 1\n",
    "    if model1_results:\n",
    "        avg_time_1 = np.mean([r['detection_time_seconds'] for r in model1_results])\n",
    "        avg_objects_1 = np.mean([r['num_objects_detected'] for r in model1_results])\n",
    "        avg_conf_1 = np.mean([r['average_confidence'] for r in model1_results if r['average_confidence'] > 0])\n",
    "        \n",
    "        print(f\"{model1_name}:\")\n",
    "        print(f\"  Average Detection Time:    {avg_time_1:.4f} seconds\")\n",
    "        print(f\"  Average Objects Detected:  {avg_objects_1:.2f} objects\")\n",
    "        print(f\"  Average Confidence Score:  {avg_conf_1:.4f}\")\n",
    "        print()\n",
    "    \n",
    "    # Calculate statistics for Model 2\n",
    "    if model2_results:\n",
    "        avg_time_2 = np.mean([r['detection_time_seconds'] for r in model2_results])\n",
    "        avg_objects_2 = np.mean([r['num_objects_detected'] for r in model2_results])\n",
    "        avg_conf_2 = np.mean([r['average_confidence'] for r in model2_results if r['average_confidence'] > 0])\n",
    "        \n",
    "        print(f\"{model2_name}:\")\n",
    "        print(f\"  Average Detection Time:    {avg_time_2:.4f} seconds\")\n",
    "        print(f\"  Average Objects Detected:  {avg_objects_2:.2f} objects\")\n",
    "        print(f\"  Average Confidence Score:  {avg_conf_2:.4f}\")\n",
    "        print()\n",
    "    \n",
    "    # Performance comparison\n",
    "    if model1_results and model2_results:\n",
    "        speed_diff = ((avg_time_2 - avg_time_1) / avg_time_1) * 100\n",
    "        objects_diff = ((avg_objects_2 - avg_objects_1) / avg_objects_1) * 100\n",
    "        conf_diff = ((avg_conf_2 - avg_conf_1) / avg_conf_1) * 100\n",
    "        \n",
    "        print(\"Performance Comparison:\")\n",
    "        print(f\"  {model2_name} is {abs(speed_diff):.1f}% {'slower' if speed_diff > 0 else 'faster'} than {model1_name}\")\n",
    "        print(f\"  {model2_name} detects {abs(objects_diff):.1f}% {'more' if objects_diff > 0 else 'fewer'} objects\")\n",
    "        print(f\"  {model2_name} has {abs(conf_diff):.1f}% {'higher' if conf_diff > 0 else 'lower'} confidence\")\n",
    "        print()\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 10: CREATE DATAFRAMES AND EXPORT TO CSV\n",
    "# ============================================================================\n",
    "\n",
    "if all_detection_results:\n",
    "    print(\"=\"*80)\n",
    "    print(\"CREATING OUTPUT FILES\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    \n",
    "    # PART A(i): Detection Comparison Table\n",
    "    detection_data = []\n",
    "    for result in all_detection_results:\n",
    "        # Get detected objects list\n",
    "        objects = ', '.join([obj['class_name'] for obj in result['detected_objects'][:5]])\n",
    "        if len(result['detected_objects']) > 5:\n",
    "            objects += f\" (+{len(result['detected_objects'])-5} more)\"\n",
    "        \n",
    "        detection_data.append({\n",
    "            'Image Name': result['image'],\n",
    "            'Model': result['model'],\n",
    "            'Detection Time (s)': result['detection_time_seconds'],\n",
    "            'Objects Detected': result['num_objects_detected'],\n",
    "            'Avg Confidence': result['average_confidence'],\n",
    "            'Detected Objects': objects if objects else 'None'\n",
    "        })\n",
    "    \n",
    "    df_detection = pd.DataFrame(detection_data)\n",
    "    df_detection.to_csv('part_a_i_detection_comparison.csv', index=False)\n",
    "    print(\"✓ Part A(i) saved to: part_a_i_detection_comparison.csv\")\n",
    "    \n",
    "    # Display detection table\n",
    "    print(\"\\nPart A(i) - Detection Comparison Table:\")\n",
    "    print(df_detection.to_string(index=False))\n",
    "    print()\n",
    "    \n",
    "    # PART A(ii): Additional Features Table\n",
    "    if all_feature_results:\n",
    "        df_features = pd.DataFrame(all_feature_results)\n",
    "        df_features.to_csv('part_a_ii_additional_features.csv', index=False)\n",
    "        print(\"✓ Part A(ii) saved to: part_a_ii_additional_features.csv\")\n",
    "        \n",
    "        # Display features table\n",
    "        print(\"\\nPart A(ii) - Additional Features Table:\")\n",
    "        print(df_features.to_string(index=False))\n",
    "        print()\n",
    "    \n",
    "    # Save detailed JSON\n",
    "    output_json = {\n",
    "        'metadata': {\n",
    "            'date_processed': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'total_images': len(image_files),\n",
    "            'models_used': [model1_name, model2_name]\n",
    "        },\n",
    "        'detection_results': all_detection_results,\n",
    "        'feature_results': all_feature_results\n",
    "    }\n",
    "    \n",
    "    with open('detailed_results.json', 'w') as f:\n",
    "        json.dump(output_json, f, indent=2)\n",
    "    print(\"✓ Detailed results saved to: detailed_results.json\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"✓ ALL FILES GENERATED SUCCESSFULLY!\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nGenerated files:\")\n",
    "    print(\"  1. part_a_i_detection_comparison.csv  - For Part A(i) in Word\")\n",
    "    print(\"  2. part_a_ii_additional_features.csv  - For Part A(ii) in Word\")\n",
    "    print(\"  3. detailed_results.json              - Full detailed results\")\n",
    "    print(\"\\nYou can now copy these tables into your Word document!\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5781089-8187-4fd7-8ffd-d8636d0e8238",
   "metadata": {},
   "outputs": [],
   "source": [
    "Part A(i) - Detection Comparison Table:\n",
    "                                                            Image Name            Model  Detection Time (s)  Objects Detected  Avg Confidence                                                  Detected Objects\n",
    "                     1000_F_187616108_v8oMYk5q7rKJXtZOfWOLoz51HcVu0JZl SSD MobileNet V2              5.6999               100          0.3788                      chair, chair, chair, chair, chair (+95 more)\n",
    "                     1000_F_187616108_v8oMYk5q7rKJXtZOfWOLoz51HcVu0JZl  EfficientDet D0             10.1763                11          0.4580               chair, potted plant, laptop, chair, chair (+6 more)\n",
    "                      360_F_310422728_gvGj4cxa8MZDbJOPws9MgQXUslt7jpxF SSD MobileNet V2              0.8915                74          0.4128                       car, car, car, car, potted plant (+69 more)\n",
    "                      360_F_310422728_gvGj4cxa8MZDbJOPws9MgQXUslt7jpxF  EfficientDet D0              2.6096                10          0.5646               car, car, car, potted plant, potted plant (+5 more)\n",
    "                                                      DSC6580-684x1024 SSD MobileNet V2              0.7558                35          0.4198           potted plant, potted plant, dog, bowl, chair (+30 more)\n",
    "                                                      DSC6580-684x1024  EfficientDet D0              2.6005                 8          0.5657               cat, cat, cat, potted plant, potted plant (+3 more)\n",
    "                         coconuts-on-beach-place-milk-260nw-1026353836 SSD MobileNet V2              0.7036                14          0.4158          bed, teddy bear, teddy bear, donut, teddy bear (+9 more)\n",
    "                         coconuts-on-beach-place-milk-260nw-1026353836  EfficientDet D0              2.3278                 3          0.3458                                       teddy bear, teddy bear, bed\n",
    "empty-classroom-scene-with-interior-decoration-and-objects-free-vector SSD MobileNet V2              1.1956               100          0.4037         chair, chair, book, dining table, dining table (+95 more)\n",
    "empty-classroom-scene-with-interior-decoration-and-objects-free-vector  EfficientDet D0              2.9359                16          0.3740 chair, dining table, dining table, chair, dining table (+11 more)\n",
    "                    img-A-Guide-to-Choosing-the-Best-Toys-for-Your-Dog SSD MobileNet V2              0.8946                 3          0.5016                                            dog, sports ball, kite\n",
    "                    img-A-Guide-to-Choosing-the-Best-Toys-for-Your-Dog  EfficientDet D0              2.4215                 2          0.8860                                                  dog, sports ball\n",
    "                                        istockphoto-1755563909-612x612 SSD MobileNet V2              0.2863                54          0.4135                        oven, oven, knife, knife, spoon (+49 more)\n",
    "                                        istockphoto-1755563909-612x612  EfficientDet D0              0.9452                 3          0.5187                                        oven, potted plant, bottle\n",
    "                                         istockphoto-495977454-612x612 SSD MobileNet V2              0.3590                 3          0.5988                                            person, person, person\n",
    "                                         istockphoto-495977454-612x612  EfficientDet D0              0.8601                 3          0.3900                                           person, frisbee, person\n",
    "                                        pexels-ash-craig-122861-376464 SSD MobileNet V2              0.2880                20          0.4161                cake, bowl, dining table, cup, sandwich (+15 more)\n",
    "                                        pexels-ash-craig-122861-376464  EfficientDet D0              0.8415                 4          0.5513                                   cake, bowl, dining table, knife\n",
    "                                     pexels-ella-olsson-572949-1640777 SSD MobileNet V2              0.3438               100          0.4202                   bowl, carrot, carrot, carrot, carrot (+95 more)\n",
    "                                     pexels-ella-olsson-572949-1640777  EfficientDet D0              0.8612                18          0.4209           fork, carrot, dining table, broccoli, carrot (+13 more)\n",
    "                                      remove-distracting-objects_step1 SSD MobileNet V2              0.3181                16          0.3785         umbrella, person, person, person, potted plant (+11 more)\n",
    "                                      remove-distracting-objects_step1  EfficientDet D0              0.8692                 4          0.4588                             boat, surfboard, surfboard, surfboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8a1358-3c92-4a7c-a780-0c51a9c25571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Across the 11 images, SSD MobileNet V2 was much faster and detected far more objects on average than EfficientDet D0, but with slightly lower \n",
    "#confidence scores. EfficientDet D0 produced fewer detections overall, yet its average confidence was about 16% higher, suggesting it is more \n",
    "#conservative but surer about the objects it does detect. Overall, SSD MobileNet V2 is better for speed and coverage, while EfficientDet D0 \n",
    "#trades speed and count for higher-confidence predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bedc99-cf7e-47cb-b1ba-af5008a2b91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Part A(ii) - Additional Features Table:\n",
    "                                                                 image dimensions  num_faces  num_eyes  edge_density_percent  brightness_level  contrast_level dominant_color_rgb  color_variance  num_corners  blur_score\n",
    "                     1000_F_187616108_v8oMYk5q7rKJXtZOfWOLoz51HcVu0JZl   1000x714          0         5                  5.95            172.85           53.84    (172, 167, 161)         2963.32         5751     1041.08\n",
    "                      360_F_310422728_gvGj4cxa8MZDbJOPws9MgQXUslt7jpxF    540x360          1         1                 22.49            156.40           67.44    (136, 121, 112)         6085.49         7775     5026.74\n",
    "                                                      DSC6580-684x1024   684x1024          0         0                 10.33            147.36           66.49    (141, 129, 116)         4776.75         8662      693.64\n",
    "                         coconuts-on-beach-place-milk-260nw-1026353836    390x280          0         1                 11.09            197.02           61.57    (160, 176, 158)         5647.67         1717     2339.14\n",
    "empty-classroom-scene-with-interior-decoration-and-objects-free-vector   1736x980          0         0                  6.15            174.16           59.41    (143, 145, 110)         5123.11         3867      446.22\n",
    "                    img-A-Guide-to-Choosing-the-Best-Toys-for-Your-Dog   1024x688          1         8                  2.38            237.50           41.14    (233, 211, 115)         4581.20          555      169.48\n",
    "                                        istockphoto-1755563909-612x612    612x408          0         1                  7.67            157.67           63.89    (156, 153, 144)         4220.36         1980      868.57\n",
    "                                         istockphoto-495977454-612x612    612x408          0         0                 11.76            188.30           71.69    (185, 167, 120)         7537.81        13263     1784.68\n",
    "                                        pexels-ash-craig-122861-376464  2841x1735          1        27                  2.07            143.41           67.05    (134, 125, 114)         5103.85         9673      143.42\n",
    "                                     pexels-ella-olsson-572949-1640777  4288x2859          7        38                  8.05            203.29           62.77    (197, 182, 162)         5391.76       114717      792.97\n",
    "                                      remove-distracting-objects_step1  1800x1200          1         0                  7.89            174.98           49.63    (130, 143, 148)         3881.24        10878      615.78\n",
    "\n",
    "✓ Detailed results saved to: detailed_results.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4815e8-1f42-46d0-8d4d-7aaf950bfc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In addition to object detection, I extracted non–deep-learning features such as image dimensions, number of faces/eyes, edge density, \n",
    "#brightness, contrast, dominant color, number of corners, and a blur score. These metrics summarize overall image complexity and quality, for example, \n",
    "#busy city and food images show higher edge density, corners, and contrast than the simpler lake and toy images. Such features could be used alongside \n",
    "#detection outputs to understand how image structure and clarity influence model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9643304a-0fd3-4ece-8f1d-95730152ffd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
